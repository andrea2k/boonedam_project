{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f7b718-bc17-41a1-a5d5-b2131206d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os as os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adagrad, Adadelta, Adamax, Nadam, Ftrl\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751d3e40-4bdd-4f26-95b2-e4ec707b209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory with data\n",
    "directories = [\"extra_data_primary\",\"extra_data_secondary\"]\n",
    "\n",
    "description_nlp = \"Log solution.csv\"\n",
    "\n",
    "csv_files = []\n",
    "solutions = {}\n",
    "descriptions = {}\n",
    "\n",
    "# get all the information within the detailed version csv\n",
    "for directory in directories:\n",
    "    filenames = listdir(directory)\n",
    "    for name in filenames:\n",
    "        if name.endswith(\".csv\"):\n",
    "            if name == description_nlp:\n",
    "                # first read all the files that contain in the log solution file\n",
    "                df = pd.read_csv(directory+\"/\"+name, encoding=\"utf-8\", sep='delimiter', header=None, engine='python')\n",
    "                for index, row in df.iterrows():\n",
    "                    if index != 0:\n",
    "                        for i in row:\n",
    "                            line = i.split(\";\")\n",
    "                            if line[0]:\n",
    "                                file = line[0]\n",
    "                                if (line[0].endswith(\".csv\")):\n",
    "                                    file = line[0].split(\".csv\")[0]\n",
    "                                # get the files with suffix equal to 'detailed_version' and its corresponding solution and short version description\n",
    "                                if os.path.exists(directory+\"/\"+file+ \"_detailed_version.csv\"):\n",
    "                                    csv_files.append(directory+\"/\"+file+ \"_detailed_version.csv\")\n",
    "                                    solutions[directory+\"/\"+file+ \"_detailed_version.csv\"] = line[2]\n",
    "                                    descriptions[directory+\"/\"+file+ \"_detailed_version.csv\"] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00180989-dd8a-44ef-a31c-f333f0864b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "errors = {}\n",
    "times = {}\n",
    "error_group_description = {}\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, encoding=\"utf-8\", sep='delimiter', header=None, engine='python')\n",
    "    group_errors = []\n",
    "    subgroup_id = []\n",
    "    subgroup_description = []\n",
    "    lines = []\n",
    "    for index, row in df.iterrows():\n",
    "        if index != 0:\n",
    "            for i in row:\n",
    "                line = i.split(\";\")\n",
    "                lines.append(line)\n",
    "    if lines:\n",
    "        lines = lines[::-1]\n",
    "        # set the group id to group the events\n",
    "        previous_group_id = lines[0][3]\n",
    "        subgroup_time = []\n",
    "        # add the time of the first event\n",
    "        subgroup_time.append(lines[0][0])\n",
    "        group_errors = []\n",
    "        subgroup_errors = []\n",
    "        subgroup_description = []\n",
    "        # if the corresponding description of event is not set\n",
    "        description_set = False\n",
    "        \n",
    "        for line in lines:\n",
    "            # get the time\n",
    "            time = line[0]\n",
    "            # get the error code and failure node id\n",
    "            error = ast.literal_eval(line[1])\n",
    "            hex_value, decimal_value = error\n",
    "            # get the group if of each event\n",
    "            group_id = line[3]\n",
    "            # get the error description\n",
    "            error_description = line[4]\n",
    "            # events with same group id are added to same subgroup\n",
    "            if group_id == previous_group_id:\n",
    "                subgroup_errors.append((int(hex_value, 16), int(decimal_value)))\n",
    "                if description_set == False:\n",
    "                    if error_description and error_description != '-':\n",
    "                        subgroup_description.append(error_description)\n",
    "                        description_set = True\n",
    "            else:\n",
    "                # warning if description of error is not set\n",
    "                if not description_set:\n",
    "                    print(\"Group\",previous_group_id,\"of\",csv_file,\"has no descriptions\")\n",
    "                # append the previous pattern\n",
    "                group_errors.append(subgroup_errors)\n",
    "                # new subgroup\n",
    "                subgroup_errors = []\n",
    "                subgroup_errors.append((int(hex_value, 16), int(decimal_value)))\n",
    "                subgroup_time.append(time)\n",
    "                # description of new subgroup\n",
    "                description_set = False\n",
    "                if error_description and error_description != '-':\n",
    "                    subgroup_description.append(error_description)\n",
    "                    description_set = True\n",
    "                previous_group_id = group_id\n",
    "        group_errors.append(subgroup_errors)\n",
    "        errors[csv_file] = group_errors\n",
    "        times[csv_file] = subgroup_time\n",
    "        error_group_description[csv_file] = subgroup_description\n",
    "    else:\n",
    "        print(csv_file,\"is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3219f62-c0af-48c3-86c7-7280a3912ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system description\n",
    "system_description = []\n",
    "# error sequences\n",
    "sequences = []\n",
    "# labes for each error sequence\n",
    "labels = []\n",
    "for csv_file in csv_files:\n",
    "    for index,sequence in enumerate(errors[csv_file]):\n",
    "        system_description.append(descriptions[csv_file])\n",
    "        sequences.append(sequence)\n",
    "        labels.append(error_group_description[csv_file][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e32d096-bbb0-4a2d-a5a1-f961ed45657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries for error codes and failure node IDs\n",
    "dict_error = {}\n",
    "dict_failure_node_id = {}\n",
    "# Initialize indexing variables for error codes and failure node IDs\n",
    "index_error = 1\n",
    "index_failure = 1\n",
    "max_length = 0\n",
    "# Iterate through each sequence in the list of sequences\n",
    "for sequence in sequences:\n",
    "    # Update max_length if the current sequence is longer than the previous maximum\n",
    "    if len(sequence) > max_length:\n",
    "        max_length = len(sequence)\n",
    "    # Iterate through each (error, failure_node_id) pair in the sequence\n",
    "    for (error,failure_node_id) in sequence:\n",
    "        # If the error is not already in the dictionary, add it with a new index\n",
    "        if error not in dict_error:\n",
    "            dict_error[error] = index_error\n",
    "            index_error += 1 # Increment the index for the next unique error\n",
    "        # If the failure_node_id is not already in the dictionary, add it with a new index\n",
    "        if failure_node_id not in dict_failure_node_id:\n",
    "            dict_failure_node_id[failure_node_id] = index_failure\n",
    "            index_failure += 1\n",
    "\n",
    "# Function to get the index of an error code from dict_error\n",
    "def get_dict_error(error):\n",
    "    if error in dict_error:\n",
    "        return dict_error[error]\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "# Function to get the index of a failure node ID from dict_failure_node_id\n",
    "def get_dict_node_id(node_id):\n",
    "    if node_id in dict_failure_node_id:\n",
    "        return dict_failure_node_id[node_id]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "090dd6a8-238d-4961-8527-bde22846293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 functions for observation level feature function\n",
    "\n",
    "def get_transformed_multi(system_description,sequences,labels):\n",
    "    transformed_data = []\n",
    "    transformed_labels = []\n",
    "    for lbl, seq, txt in zip(labels, sequences, system_description):\n",
    "        transformed_sequence = [(txt, feat) for feat in seq]\n",
    "        transformed_data.append(transformed_sequence)\n",
    "        transformed_labels.append([lbl] * len(seq))\n",
    "    return transformed_data,transformed_labels\n",
    "\n",
    "def multi_label_extract_features(observation_sequence, t):\n",
    "    normalized = True\n",
    "    if normalized:\n",
    "        x = len(dict_error)\n",
    "        y = len(dict_failure_node_id)\n",
    "    else:\n",
    "        x = 1\n",
    "        y = 1\n",
    "\n",
    "    text = observation_sequence[t][0]\n",
    "    if t == 0:  \n",
    "        features = {\n",
    "            'observation': observation_sequence[t][0],\n",
    "            'error': get_dict_error(observation_sequence[t][1][0])/x,\n",
    "            'failure_node': get_dict_node_id(observation_sequence[t][1][1])/y,\n",
    "        }\n",
    "    else:\n",
    "        features = {\n",
    "            'observation': \" \",\n",
    "            'error': get_dict_error(observation_sequence[t][1][0])/x,\n",
    "            'failure_node': get_dict_node_id(observation_sequence[t][1][1])/y,\n",
    "        }\n",
    "    if t == 0:\n",
    "        features.update({\n",
    "            'prev_observation': '<START>',\n",
    "            'prev_error': '<START>',\n",
    "            'prev_feature': '<START>',\n",
    "        })\n",
    "    elif t == 1:\n",
    "        features.update({\n",
    "            'prev_observation': observation_sequence[t-1][0],\n",
    "            'prev_error': get_dict_error(observation_sequence[t-1][1][0])/x,\n",
    "            'prev_failure_node': get_dict_node_id(observation_sequence[t-1][1][1])/y,\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'prev_observation': \" \",\n",
    "            'prev_error': get_dict_error(observation_sequence[t-1][1][0])/x,\n",
    "            'prev_failure_node': get_dict_node_id(observation_sequence[t-1][1][1])/y,\n",
    "        })\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_features_multi_label(transformed_data):\n",
    "    X_train_features = []\n",
    "    for data in transformed_data:\n",
    "        X_train_features.append([multi_label_extract_features(data, i) for i in range(len(data))])\n",
    "    return X_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e849473b-11fe-4623-805d-ad358ea6f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 functions for sequence level feature function\n",
    "def get_transformed_sequence(system_description,sequences):\n",
    "    length = len(system_description)\n",
    "    observation_sequences = []\n",
    "    for i in range(length):\n",
    "        observation_sequences.append((system_description[i],sequences[i]))\n",
    "    return observation_sequences\n",
    "\n",
    "def single_label_extract_features(observation_sequence):\n",
    "    features = {}\n",
    "    normalized = True\n",
    "    if normalized:\n",
    "        x = len(dict_error)\n",
    "        y = len(dict_failure_node_id)\n",
    "    else:\n",
    "        x = 1\n",
    "        y = 1\n",
    "    features['observation'] = observation_sequence[0]\n",
    "    event_sequence = observation_sequence[1]\n",
    "    length = len(event_sequence)\n",
    "    for i in range(max_length):\n",
    "        if i < length:\n",
    "            features[f'error_{i}'] = get_dict_error(event_sequence[i][0])/x\n",
    "            features[f'failure_node_{i}'] = get_dict_node_id(event_sequence[i][1])/y\n",
    "        else:\n",
    "            features[f'error_{i}'] = 0\n",
    "            features[f'failure_node_{i}'] = 0\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_features_sequence_label(observation_sequences):\n",
    "    X_train_sequence = []\n",
    "    y_train_sequence = []\n",
    "    for observation_sequence in observation_sequences:\n",
    "        X_train_sequence.append([single_label_extract_features(observation_sequence)])\n",
    "    for label in labels:\n",
    "        y_train_sequence.append([label])\n",
    "    return X_train_sequence, y_train_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f2a6a33-f50d-4f7e-9fe6-c5193e20110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the system descriptions to prepare them for LSTM input\n",
    "description_tokenizer = Tokenizer()\n",
    "description_tokenizer.fit_on_texts(system_description)\n",
    "text_sequences = description_tokenizer.texts_to_sequences(system_description)\n",
    "\n",
    "# Find the maximum length of the sequences to ensure consistent input shape for the LSTM\n",
    "max_text_len = max(len(seq) for seq in text_sequences)\n",
    "# Pad all sequences to the same length as the longest sequence, adding zeros to the end (post-padding)\n",
    "lstm_description = pad_sequences(text_sequences, maxlen=max_text_len, padding='post')\n",
    "\n",
    "\n",
    "# Function to transform each event sequence into a fixed-length sequence of numerical values\n",
    "def transform_sequence(seq):\n",
    "    # Convert each (error, node_id) pair in the sequence to normalized values based on dictionaries\n",
    "    transformed = [(get_dict_error(error)/len(dict_error), get_dict_node_id(node_id)/len(dict_failure_node_id)) for error, node_id in seq]\n",
    "    while len(transformed) < max_length:\n",
    "        transformed.append((0, 0))\n",
    "    return transformed\n",
    "\n",
    "# Function to pad a list of event sequences for LSTM input\n",
    "def pad_events_lstm(sequences):\n",
    "    event_sequences_padded = [transform_sequence(seq) for seq in sequences]\n",
    "    return event_sequences_padded\n",
    "\n",
    "# Apply padding and transformation to the original sequences to prepare for LSTM training\n",
    "lstm_sequences = pad_events_lstm(sequences)\n",
    "\n",
    "# Tokenize the labels for the output\n",
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(labels)\n",
    "label_sequences = label_tokenizer.texts_to_sequences(labels)\n",
    "\n",
    "# Initialize variables to map unique labels to numerical values\n",
    "numerical_value = 1\n",
    "lstm_label = [] # List to store the numerical representation of the labels\n",
    "dict_label = {} # Dictionary to map original label sequences to their numerical representation\n",
    "for index,label_sequence in enumerate(label_sequences):\n",
    "    found = False\n",
    "    for key in dict_label:\n",
    "        # if the current label sequence is already in the dictionary, map to the existing numerical value\n",
    "        if dict_label[key][1] == label_sequence:\n",
    "            found = True\n",
    "            lstm_label.append(dict_label[key][0])\n",
    "    if not found:\n",
    "        # If the label sequence is not found in the dictionary, create and map to the incremented numerical value\n",
    "        key = labels[index]\n",
    "        dict_label[key] = [numerical_value,label_sequence]\n",
    "        lstm_label.append(numerical_value)\n",
    "        numerical_value += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf61aa5-41f4-43c2-8336-f1d46ac60e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertng the data for model training\n",
    "lstm_label_categorical = to_categorical(np.array(lstm_label) - 1)\n",
    "lstm_description = np.array(lstm_description)\n",
    "lstm_sequences = np.array(lstm_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "811e7eda-dc6e-4f25-881c-73dbd013babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique classes in y_train: 38\n",
      "Number of unique classes in y_test: 14\n",
      "Classes in y_train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 31 32 33 34 35 36 37 38]\n",
      "Counts in y_train: [ 3  2 20  1  1  1  2  3  1  2  1  4  2  1  1  1  1  2  1  2  1  2  3  2\n",
      "  2  1  5  2  2  2  3  4  1  2  1  6  1  7]\n",
      "Classes in y_test: [ 0  2  3  4  7 11 19 21 23 26 30 31 32 33]\n",
      "Counts in y_test: [1 9 1 1 1 1 1 1 1 1 2 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into training and test dataset\n",
    "X_train_desc, X_test_desc, X_train_seq, X_test_seq, y_train, y_test = train_test_split(lstm_description, lstm_sequences, lstm_label_categorical, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c144f27e-ac4f-4c2b-b12b-c0b72fcf8254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n",
      "[0.01, 0.05, 0.001, 0.005, 0.0001, 0.0005]\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter values\n",
    "param_grid = {\n",
    "    'layers': np.arange(1, 6, 1),\n",
    "    'neurons': np.arange(16,64,8),\n",
    "    'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
    "    'learning_rate': [1e-2,5e-2,1e-3,5e-3,1e-4,5e-4],\n",
    "    'epochs': np.arange(50, 250, 50),\n",
    "    'batch_size': np.arange(8,32,8)\n",
    "}\n",
    "\n",
    "param_combinations = list(product(\n",
    "    param_grid['layers'], \n",
    "    param_grid['neurons'], \n",
    "    param_grid['optimizer'], \n",
    "    param_grid['learning_rate'], \n",
    "    param_grid['epochs'], \n",
    "    param_grid['batch_size']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd8d7914-82ef-4af6-a386-5aeb5170aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # List to store the results of each hyperparameter configuration\n",
    "results = []\n",
    "\n",
    "for params in param_combinations:\n",
    "    layers, neurons, optimizer, learning_rate, epochs, batch_size = params\n",
    "    neurons = int(neurons)  # Ensure that 'neurons' is an integer\n",
    "    \n",
    "    # Define input and LSTM layers for the text data\n",
    "    text_input = Input(shape=(X_train_desc.shape[1],), name='text_input')\n",
    "    embedding = Embedding(input_dim=np.max(X_train_desc) + 1, output_dim=50)(text_input)\n",
    "    x = LSTM(neurons, return_sequences=True)(embedding)\n",
    "    \n",
    "    # Add additional LSTM layers if specified\n",
    "    for _ in range(layers - 2):\n",
    "        x = LSTM(neurons, return_sequences=True)(x)\n",
    "    \n",
    "    # Final LSTM layer for text input\n",
    "    text_lstm = LSTM(neurons)(x)\n",
    "    \n",
    "    # Define input and LSTM layers for the sequential data (event sequences)\n",
    "    seq_input = Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2]), name='seq_input')\n",
    "    y = LSTM(neurons, return_sequences=True)(seq_input)\n",
    "    \n",
    "    # Add additional LSTM layers if specified\n",
    "    for _ in range(layers - 2):\n",
    "        y = LSTM(neurons, return_sequences=True)(y)\n",
    "    \n",
    "    # Final LSTM layer for sequence input\n",
    "    seq_lstm = LSTM(neurons)(y)\n",
    "    \n",
    "    # Concatenate the outputs of the text and sequence LSTM branches\n",
    "    concat = Concatenate()([text_lstm, seq_lstm])\n",
    "    # Output layer for classification, using softmax activation for multi-class classification\n",
    "    output = Dense(y_train.shape[1], activation='softmax')(concat)\n",
    "\n",
    "    # Create the model using the specified input and output layers\n",
    "    model = Model(inputs=[text_input, seq_input], outputs=output)\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    # Compile the model with categorical crossentropy loss and accuracy as the metric\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model using the training data and specified hyperparameters\n",
    "    model.fit([X_train_desc, X_train_seq], y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict([X_test_desc, X_test_seq])\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calculate performance metrics for the model\n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    precision = precision_score(y_test_classes, y_pred_classes, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test_classes, y_pred_classes, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Append the current hyperparameter configuration and performance metrics to the results list\n",
    "    results.append({\n",
    "        'layers': layers,\n",
    "        'neurons': neurons,\n",
    "        'optimizer': optimizer,\n",
    "        'learning_rate': learning_rate,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'accuracy': round(accuracy, 4),\n",
    "        'precision': round(precision, 4),\n",
    "        'recall': round(recall, 4),\n",
    "        'f1_score': round(f1, 4)\n",
    "    })\n",
    "\n",
    "# Save the configuration and result in csv file\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"lstm_hyperparameter_results.csv\", sep=';', encoding=\"utf-8\", index=True)\n",
    "\n",
    "print(\"Best accuracy: index =\", results_df['accuracy'].idxmax(), results_df.loc[results_df['accuracy'].idxmax()])\n",
    "print(\"Best precision: index =\", results_df['precision'].idxmax(), results_df.loc[results_df['precision'].idxmax()])\n",
    "print(\"Best recall: index =\", results_df['recall'].idxmax(), results_df.loc[results_df['recall'].idxmax()])\n",
    "print(\"Best f1_score: index =\", results_df['f1_score'].idxmax(), results_df.loc[results_df['f1_score'].idxmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d938479-2aca-4ddc-b005-593edd657f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249600\n"
     ]
    }
   ],
   "source": [
    "# Transform the data for first CRF model usage\n",
    "transformed_data, y_train_multi = get_transformed_multi(system_description,sequences,labels)\n",
    "X_train_multi = get_features_multi_label(transformed_data)\n",
    "\n",
    "# Split the dataset\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_train_multi, y_train_multi, test_size=0.2, random_state=0)\n",
    "\n",
    "# hyperparameter values\n",
    "param_grid = {\n",
    "    'c1': np.arange(0, 1, 0.1),\n",
    "    'c2': np.arange(0, 1, 0.1),\n",
    "    'min_freq': np.arange(0, 8, 1),\n",
    "    'max_iterations': np.arange(50, 2000, 50),\n",
    "    'all_possible_transitions': [True, False],\n",
    "    'all_possible_states': [True, False],\n",
    "    'algorithms':['lbfgs','l2sgd']\n",
    "}\n",
    "\n",
    "param_combinations = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa83cb89-2b5a-43fa-adc0-bd7d0cbaefe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: index = 34328 c1                             0.1\n",
      "c2                             0.0\n",
      "min_freq                         0\n",
      "max_iterations                 100\n",
      "all_possible_transitions     False\n",
      "all_possible_states           True\n",
      "algorithms                   lbfgs\n",
      "accuracy                    0.6429\n",
      "precision                   0.7847\n",
      "recall                      0.8491\n",
      "f1_score                    0.8087\n",
      "Name: 34328, dtype: object\n",
      "precision: index = 140736 c1                             0.0\n",
      "c2                             0.1\n",
      "min_freq                         0\n",
      "max_iterations                 200\n",
      "all_possible_transitions      True\n",
      "all_possible_states           True\n",
      "algorithms                   l2sgd\n",
      "accuracy                    0.2321\n",
      "precision                   0.9194\n",
      "recall                      0.2347\n",
      "f1_score                    0.3542\n",
      "Name: 140736, dtype: object\n",
      "recall: index = 143913 c1                             0.0\n",
      "c2                             0.1\n",
      "min_freq                         1\n",
      "max_iterations                 550\n",
      "all_possible_transitions      True\n",
      "all_possible_states           True\n",
      "algorithms                   l2sgd\n",
      "accuracy                    0.5893\n",
      "precision                   0.6561\n",
      "recall                      0.9245\n",
      "f1_score                     0.765\n",
      "Name: 143913, dtype: object\n",
      "f1_score: index = 34328 c1                             0.1\n",
      "c2                             0.0\n",
      "min_freq                         0\n",
      "max_iterations                 100\n",
      "all_possible_transitions     False\n",
      "all_possible_states           True\n",
      "algorithms                   lbfgs\n",
      "accuracy                    0.6429\n",
      "precision                   0.7847\n",
      "recall                      0.8491\n",
      "f1_score                    0.8087\n",
      "Name: 34328, dtype: object\n"
     ]
    }
   ],
   "source": [
    " # List to store the results of each hyperparameter configuration\n",
    "results = []\n",
    "\n",
    "for params in param_combinations:\n",
    "    if params['algorithms'] == 'lbfgs':\n",
    "        crf = sklearn_crfsuite.CRF(\n",
    "            algorithm=params['algorithms'],\n",
    "            c1=params['c1'],\n",
    "            c2=params['c2'],\n",
    "            min_freq=params['min_freq'],\n",
    "            max_iterations=params['max_iterations'],\n",
    "            all_possible_transitions=params['all_possible_transitions'],\n",
    "            all_possible_states=params['all_possible_states']\n",
    "        )\n",
    "    else:\n",
    "        crf = sklearn_crfsuite.CRF(\n",
    "            algorithm=params['algorithms'],\n",
    "            c2=params['c2'],\n",
    "            min_freq=params['min_freq'],\n",
    "            max_iterations=params['max_iterations'],\n",
    "            all_possible_transitions=params['all_possible_transitions'],\n",
    "            all_possible_states=params['all_possible_states']\n",
    "        )\n",
    "    \n",
    "    # Train the model\n",
    "    crf.fit(X_train_multi, y_train_multi)\n",
    "    # Calculate the prediction\n",
    "    y_pred_multi = crf.predict(X_test_multi)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = metrics.flat_accuracy_score(y_test_multi, y_pred_multi)\n",
    "    precision = metrics.flat_precision_score(y_test_multi, y_pred_multi, average='weighted', labels=labels, zero_division=0)\n",
    "    recall = metrics.flat_recall_score(y_test_multi, y_pred_multi, average='weighted', labels=labels, zero_division=0)\n",
    "    f1 = metrics.flat_f1_score(y_test_multi, y_pred_multi, average='weighted', labels=labels, zero_division=0)\n",
    "    \n",
    "    # Store the results in a single line format\n",
    "    if params['algorithms'] == 'lbfgs':\n",
    "        results.append({\n",
    "            'c1': params['c1'],\n",
    "            'c2': params['c2'],\n",
    "            'min_freq': params['min_freq'],\n",
    "            'max_iterations': params['max_iterations'],\n",
    "            'all_possible_transitions': params['all_possible_transitions'],\n",
    "            'all_possible_states': params['all_possible_states'],\n",
    "            'algorithms':params['algorithms'],\n",
    "            'accuracy': round(accuracy,4),\n",
    "            'precision': round(precision,4),\n",
    "            'recall': round(recall,4),\n",
    "            'f1_score': round(f1,4)\n",
    "        })\n",
    "    else:\n",
    "        results.append({\n",
    "            'c1': 0,\n",
    "            'c2': params['c2'],\n",
    "            'min_freq': params['min_freq'],\n",
    "            'max_iterations': params['max_iterations'],\n",
    "            'all_possible_transitions': params['all_possible_transitions'],\n",
    "            'all_possible_states': params['all_possible_states'],\n",
    "            'algorithms':params['algorithms'],\n",
    "            'accuracy': round(accuracy,4),\n",
    "            'precision': round(precision,4),\n",
    "            'recall': round(recall,4),\n",
    "            'f1_score': round(f1,4)\n",
    "        })\n",
    "        \n",
    "# Save the configuration and result in csv file\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"multi_hyperparameter_results.csv\",sep=';' , encoding=\"utf-8\", index=True)\n",
    "\n",
    "print(\"accuracy: index =\",results_df['accuracy'].idxmax(),results_df.loc[results_df['accuracy'].idxmax()])\n",
    "\n",
    "print(\"precision: index =\",results_df['precision'].idxmax(),results_df.loc[results_df['precision'].idxmax()])\n",
    "\n",
    "print(\"recall: index =\",results_df['recall'].idxmax(),results_df.loc[results_df['recall'].idxmax()])\n",
    "\n",
    "print(\"f1_score: index =\",results_df['f1_score'].idxmax(),results_df.loc[results_df['f1_score'].idxmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f2e2055-4adc-46c3-becc-df7d63886068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data for second CRF model usage\n",
    "observation_sequences = get_transformed_sequence(system_description,sequences)\n",
    "X_train_sequence, y_train_sequence = get_features_sequence_label(observation_sequences)\n",
    "\n",
    "# Split the datasest\n",
    "X_train_sequence, X_test_sequence, y_train_sequence, y_test_sequence = train_test_split(X_train_sequence,  y_train_sequence, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68fb95ff-38d8-4784-bd17-070c46ef1268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: index = 0 c1                             0.0\n",
      "c2                             0.0\n",
      "min_freq                         0\n",
      "max_iterations                  50\n",
      "all_possible_transitions      True\n",
      "all_possible_states           True\n",
      "algorithms                   lbfgs\n",
      "accuracy                      0.56\n",
      "precision                   0.8283\n",
      "recall                      0.7329\n",
      "f1_score                    0.7683\n",
      "Name: 0, dtype: object\n",
      "precision: index = 0 c1                             0.0\n",
      "c2                             0.0\n",
      "min_freq                         0\n",
      "max_iterations                  50\n",
      "all_possible_transitions      True\n",
      "all_possible_states           True\n",
      "algorithms                   lbfgs\n",
      "accuracy                      0.56\n",
      "precision                   0.8283\n",
      "recall                      0.7329\n",
      "f1_score                    0.7683\n",
      "Name: 0, dtype: object\n",
      "recall: index = 68640 c1                             0.2\n",
      "c2                             0.0\n",
      "min_freq                         0\n",
      "max_iterations                  50\n",
      "all_possible_transitions      True\n",
      "all_possible_states          False\n",
      "algorithms                   lbfgs\n",
      "accuracy                      0.52\n",
      "precision                   0.5565\n",
      "recall                       0.873\n",
      "f1_score                    0.6782\n",
      "Name: 68640, dtype: object\n",
      "f1_score: index = 0 c1                             0.0\n",
      "c2                             0.0\n",
      "min_freq                         0\n",
      "max_iterations                  50\n",
      "all_possible_transitions      True\n",
      "all_possible_states           True\n",
      "algorithms                   lbfgs\n",
      "accuracy                      0.56\n",
      "precision                   0.8283\n",
      "recall                      0.7329\n",
      "f1_score                    0.7683\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    " # List to store the results of each hyperparameter configuration\n",
    "results = []\n",
    "\n",
    "for params in param_combinations:\n",
    "    if params['algorithms'] == 'lbfgs':\n",
    "        crf = sklearn_crfsuite.CRF(\n",
    "            algorithm=params['algorithms'],\n",
    "            c1=params['c1'],\n",
    "            c2=params['c2'],\n",
    "            min_freq=params['min_freq'],\n",
    "            max_iterations=params['max_iterations'],\n",
    "            all_possible_transitions=params['all_possible_transitions'],\n",
    "            all_possible_states=params['all_possible_states']\n",
    "        )\n",
    "    else:\n",
    "        crf = sklearn_crfsuite.CRF(\n",
    "            algorithm=params['algorithms'],\n",
    "            c2=params['c2'],\n",
    "            min_freq=params['min_freq'],\n",
    "            max_iterations=params['max_iterations'],\n",
    "            all_possible_transitions=params['all_possible_transitions'],\n",
    "            all_possible_states=params['all_possible_states']\n",
    "        )\n",
    "    \n",
    "    # Train the model\n",
    "    crf.fit(X_train_sequence, y_train_sequence)\n",
    "    # Calculate the prediction\n",
    "    y_pred_sequence = crf.predict(X_test_sequence)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = metrics.flat_accuracy_score(y_test_sequence, y_pred_sequence)\n",
    "    precision = metrics.flat_precision_score(y_test_sequence, y_pred_sequence, average='weighted', labels=labels, zero_division=0)\n",
    "    recall = metrics.flat_recall_score(y_test_sequence, y_pred_sequence, average='weighted', labels=labels, zero_division=0)\n",
    "    f1 = metrics.flat_f1_score(y_test_sequence, y_pred_sequence, average='weighted', labels=labels, zero_division=0)\n",
    "    \n",
    "    # Store the results in a single line format\n",
    "    if params['algorithms'] == 'lbfgs':\n",
    "        results.append({\n",
    "            'c1': params['c1'],\n",
    "            'c2': params['c2'],\n",
    "            'min_freq': params['min_freq'],\n",
    "            'max_iterations': params['max_iterations'],\n",
    "            'all_possible_transitions': params['all_possible_transitions'],\n",
    "            'all_possible_states': params['all_possible_states'],\n",
    "            'algorithms':params['algorithms'],\n",
    "            'accuracy': round(accuracy,4),\n",
    "            'precision': round(precision,4),\n",
    "            'recall': round(recall,4),\n",
    "            'f1_score': round(f1,4)\n",
    "        })\n",
    "    else:\n",
    "        results.append({\n",
    "            'c1': 0,\n",
    "            'c2': params['c2'],\n",
    "            'min_freq': params['min_freq'],\n",
    "            'max_iterations': params['max_iterations'],\n",
    "            'all_possible_transitions': params['all_possible_transitions'],\n",
    "            'all_possible_states': params['all_possible_states'],\n",
    "            'algorithms':params['algorithms'],\n",
    "            'accuracy': round(accuracy,4),\n",
    "            'precision': round(precision,4),\n",
    "            'recall': round(recall,4),\n",
    "            'f1_score': round(f1,4)\n",
    "        })\n",
    "\n",
    "# Save the configuration and results in csv file\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"sequenced_hyperparameter_results.csv\",sep=';' , encoding=\"utf-8\", index=True)\n",
    "\n",
    "print(\"accuracy: index =\",results_df['accuracy'].idxmax(),results_df.loc[results_df['accuracy'].idxmax()])\n",
    "\n",
    "print(\"precision: index =\",results_df['precision'].idxmax(),results_df.loc[results_df['precision'].idxmax()])\n",
    "\n",
    "print(\"recall: index =\",results_df['recall'].idxmax(),results_df.loc[results_df['recall'].idxmax()])\n",
    "\n",
    "print(\"f1_score: index =\",results_df['f1_score'].idxmax(),results_df.loc[results_df['f1_score'].idxmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a21162d-f973-43d6-8ea5-cac2ced718bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files again\n",
    "lstm_results = pd.read_csv('lstm_hyperparameter_results.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af9ab1da-16cf-4dd2-9400-2df114fd8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5_by_metric(df, optimizer, metric):\n",
    "    return df[df['optimizer'] == optimizer].nlargest(5, metric)\n",
    "\n",
    "def extract_params(top_5_df):\n",
    "    params_list = []\n",
    "    for _, row in top_5_df.iterrows():\n",
    "        params = {\n",
    "            'layers': row['layers'],\n",
    "            'neurons': row['neurons'],\n",
    "            'learning_rate': row['learning_rate'],\n",
    "            'epochs': row['epochs'],\n",
    "            'batch_size': row['batch_size'],\n",
    "        }\n",
    "        params_list.append(params)\n",
    "    return params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7db75739-b37f-4561-9210-fca5a474b7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "top_5_lstm_adam_accuracy = get_top_5_by_metric(lstm_results, 'adam', 'accuracy')\n",
    "top_5_lstm_adam_precision = get_top_5_by_metric(lstm_results, 'adam', 'precision')\n",
    "top_5_lstm_adam_recall = get_top_5_by_metric(lstm_results, 'adam', 'recall')\n",
    "top_5_lstm_adam_f1_score = get_top_5_by_metric(lstm_results, 'adam', 'f1_score')\n",
    "\n",
    "top_5_adam_accuracy_params = extract_params(top_5_lstm_adam_accuracy)\n",
    "top_5_adam_precision_params = extract_params(top_5_lstm_adam_precision)\n",
    "top_5_adam_recall_params = extract_params(top_5_lstm_adam_recall)\n",
    "top_5_adam_f1_score_params = extract_params(top_5_lstm_adam_f1_score)\n",
    "\n",
    "top_5_lstm_rmsprop_accuracy = get_top_5_by_metric(lstm_results, 'rmsprop', 'accuracy')\n",
    "top_5_lstm_rmsprop_precision = get_top_5_by_metric(lstm_results, 'rmsprop', 'precision')\n",
    "top_5_lstm_rmsprop_recall = get_top_5_by_metric(lstm_results, 'rmsprop', 'recall')\n",
    "top_5_lstm_rmsprop_f1_score = get_top_5_by_metric(lstm_results, 'rmsprop', 'f1_score')\n",
    "\n",
    "top_5_rmsprop_accuracy_params = extract_params(top_5_lstm_rmsprop_accuracy)\n",
    "top_5_rmsprop_precision_params = extract_params(top_5_lstm_rmsprop_precision)\n",
    "top_5_rmsprop_recall_params = extract_params(top_5_lstm_rmsprop_recall)\n",
    "top_5_rmsprop_f1_score_params = extract_params(top_5_lstm_rmsprop_f1_score)\n",
    "\n",
    "top_5_lstm_sgd_accuracy = get_top_5_by_metric(lstm_results, 'sgd', 'accuracy')\n",
    "top_5_lstm_sgd_precision = get_top_5_by_metric(lstm_results, 'sgd', 'precision')\n",
    "top_5_lstm_sgd_recall = get_top_5_by_metric(lstm_results, 'sgd', 'recall')\n",
    "top_5_lstm_sgd_f1_score = get_top_5_by_metric(lstm_results, 'sgd', 'f1_score')\n",
    "\n",
    "top_5_sgd_accuracy_params = extract_params(top_5_lstm_sgd_accuracy)\n",
    "top_5_sgd_precision_params = extract_params(top_5_lstm_sgd_precision)\n",
    "top_5_sgd_recall_params = extract_params(top_5_lstm_sgd_recall)\n",
    "top_5_sgd_f1_score_params = extract_params(top_5_lstm_sgd_f1_score)\n",
    "\n",
    "params_list = top_5_adam_accuracy_params + top_5_adam_precision_params + top_5_adam_recall_params + top_5_adam_f1_score_params + top_5_rmsprop_accuracy_params + top_5_rmsprop_precision_params + top_5_rmsprop_recall_params + top_5_rmsprop_f1_score_params + top_5_sgd_accuracy_params + top_5_sgd_precision_params + top_5_sgd_recall_params + top_5_sgd_f1_score_params\n",
    "\n",
    "unique_params_set = {tuple(param.items()) for param in params_list}\n",
    "unique_params_list = [dict(param) for param in unique_params_set]\n",
    "\n",
    "print(len(unique_params_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e010c89f-8964-4880-a21e-71f61b2c654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5_by_metric(df, optimizer, metric):\n",
    "    return df[df['algorithms'] == optimizer].nlargest(5, metric)\n",
    "\n",
    "def extract_params(top_5_df,feature_function):\n",
    "    params_list = []\n",
    "    for _, row in top_5_df.iterrows():\n",
    "        params = {\n",
    "            'feature_function': feature_function,\n",
    "            'algorithm': row['algorithms'],\n",
    "            'c1': row['c1'],\n",
    "            'c2': row['c2'],\n",
    "            'max_iterations': row['max_iterations'],\n",
    "            'min_freq': row['min_freq'],\n",
    "            'possible_states': row['all_possible_states'],\n",
    "            'possible_transitions': row['all_possible_transitions'],\n",
    "            'accuracy': row['accuracy'],\n",
    "            'precision': row['precision'],\n",
    "            'recall': row['recall'],\n",
    "            'f1_score': row['f1_score']\n",
    "        }\n",
    "        params_list.append(params)\n",
    "    return params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7e1513d-c1a0-4c6e-95bd-a9d84658a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0   c1   c2  min_freq  max_iterations  \\\n",
      "34328       34328  0.1  0.0         0             100   \n",
      "65536       65536  0.1  0.0         0             150   \n",
      "65544       65544  0.1  0.0         0             200   \n",
      "65552       65552  0.1  0.0         0             250   \n",
      "65560       65560  0.1  0.0         0             300   \n",
      "\n",
      "       all_possible_transitions  all_possible_states algorithms  accuracy  \\\n",
      "34328                     False                 True      lbfgs    0.6429   \n",
      "65536                      True                False      lbfgs    0.6071   \n",
      "65544                      True                False      lbfgs    0.6071   \n",
      "65552                      True                False      lbfgs    0.6071   \n",
      "65560                      True                False      lbfgs    0.6071   \n",
      "\n",
      "       precision  recall  f1_score  \n",
      "34328     0.7847  0.8491    0.8087  \n",
      "65536     0.7164  0.8715    0.7781  \n",
      "65544     0.7164  0.8715    0.7781  \n",
      "65552     0.7164  0.8715    0.7781  \n",
      "65560     0.7164  0.8715    0.7781  \n",
      "        Unnamed: 0   c1   c2  min_freq  max_iterations  \\\n",
      "143913      143913  0.0  0.1         1             550   \n",
      "175200      175200  0.0  0.1         0            1100   \n",
      "184465      184465  0.0  0.1         1             500   \n",
      "240784      240784  0.0  0.1         0            1500   \n",
      "125248      125248  0.0  0.1         0             900   \n",
      "\n",
      "        all_possible_transitions  all_possible_states algorithms  accuracy  \\\n",
      "143913                      True                 True      l2sgd    0.5893   \n",
      "175200                     False                 True      l2sgd    0.5893   \n",
      "184465                     False                 True      l2sgd    0.5893   \n",
      "240784                     False                False      l2sgd    0.5893   \n",
      "125248                      True                 True      l2sgd    0.5714   \n",
      "\n",
      "        precision  recall  f1_score  \n",
      "143913     0.6561  0.9245    0.7650  \n",
      "175200     0.6944  0.9233    0.7907  \n",
      "184465     0.5845  0.9245    0.7145  \n",
      "240784     0.6561  0.9245    0.7650  \n",
      "125248     0.6513  0.9198    0.7601  \n"
     ]
    }
   ],
   "source": [
    "crf_multi_results = pd.read_csv('multi_hyperparameter_results.csv', sep=';')\n",
    "\n",
    "top_5_multi_lbfgs_accuracy = get_top_5_by_metric(crf_multi_results, 'lbfgs', 'accuracy')\n",
    "top_5_multi_lbfgs_precision = get_top_5_by_metric(crf_multi_results, 'lbfgs', 'precision')\n",
    "top_5_multi_lbfgs_recall = get_top_5_by_metric(crf_multi_results, 'lbfgs', 'recall')\n",
    "# top_5_multi_lbfgs_f1_score = get_top_5_by_metric(crf_multi_results, 'lbfgs', 'f1_score')\n",
    "\n",
    "print(top_5_multi_lbfgs_accuracy)\n",
    "top_5_multi_lbfgs_accuracy_params = extract_params(top_5_multi_lbfgs_accuracy,'observation-level')\n",
    "top_5_multi_lbfgs_precision_params = extract_params(top_5_multi_lbfgs_precision,'observation-level')\n",
    "top_5_multi_lbfgs_recall_params = extract_params(top_5_multi_lbfgs_recall,'observation-level')\n",
    "top_5_multi_lbfgs_f1_score_params = extract_params(top_5_multi_lbfgs_f1_score,'observation-level')\n",
    "\n",
    "top_5_multi_l2sgd_accuracy = get_top_5_by_metric(crf_multi_results, 'l2sgd', 'accuracy')\n",
    "top_5_multi_l2sgd_precision = get_top_5_by_metric(crf_multi_results, 'l2sgd', 'precision')\n",
    "top_5_multi_l2sgd_recall = get_top_5_by_metric(crf_multi_results, 'l2sgd', 'recall')\n",
    "top_5_multi_l2sgd_f1_score = get_top_5_by_metric(crf_multi_results, 'l2sgd', 'f1_score')\n",
    "print(top_5_multi_l2sgd_accuracy)\n",
    "\n",
    "top_5_multi_l2sgd_accuracy_params = extract_params(top_5_multi_l2sgd_accuracy,'observation-level')\n",
    "top_5_multi_l2sgd_precision_params = extract_params(top_5_multi_l2sgd_precision,'observation-level')\n",
    "top_5_multi_l2sgd_recall_params = extract_params(top_5_multi_l2sgd_recall,'observation-level')\n",
    "top_5_multi_l2sgd_f1_score_params = extract_params(top_5_multi_l2sgd_f1_score,'observation-level')\n",
    "\n",
    "params_list = top_5_multi_lbfgs_accuracy_params + top_5_multi_lbfgs_precision_params + top_5_multi_lbfgs_recall_params + top_5_multi_lbfgs_f1_score_params + top_5_multi_l2sgd_accuracy_params + top_5_multi_l2sgd_precision_params + top_5_multi_l2sgd_recall_params + top_5_multi_l2sgd_f1_score_params  \n",
    "unique_params_set = {tuple(param.items()) for param in params_list}\n",
    "unique_params_list = [dict(param) for param in unique_params_set]\n",
    "\n",
    "best_results_df = pd.DataFrame(unique_params_list)\n",
    "\n",
    "best_results_df.to_csv('best_results_multi.csv', sep=';', encoding=\"utf-8\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16474133-5a4a-43d6-acdc-e80fa95fe9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0   c1   c2  min_freq  max_iterations  \\\n",
      "0               0  0.0  0.0         0              50   \n",
      "31200       31200  0.0  0.0         0              50   \n",
      "62400       62400  0.0  0.0         0              50   \n",
      "62408       62408  0.0  0.0         0             100   \n",
      "62416       62416  0.0  0.0         0             150   \n",
      "\n",
      "       all_possible_transitions  all_possible_states algorithms  accuracy  \\\n",
      "0                          True                 True      lbfgs      0.56   \n",
      "31200                     False                 True      lbfgs      0.56   \n",
      "62400                      True                False      lbfgs      0.56   \n",
      "62408                      True                False      lbfgs      0.56   \n",
      "62416                      True                False      lbfgs      0.56   \n",
      "\n",
      "       precision  recall  f1_score  \n",
      "0         0.8283  0.7329    0.7683  \n",
      "31200     0.8283  0.7329    0.7683  \n",
      "62400     0.6973  0.8143    0.7392  \n",
      "62408     0.7485  0.7329    0.7307  \n",
      "62416     0.7524  0.7329    0.7351  \n",
      "        Unnamed: 0   c1   c2  min_freq  max_iterations  \\\n",
      "125112      125112  0.0  0.1         0              50   \n",
      "125120      125120  0.0  0.1         0             100   \n",
      "125121      125121  0.0  0.1         1             100   \n",
      "125122      125122  0.0  0.1         2             100   \n",
      "125128      125128  0.0  0.1         0             150   \n",
      "\n",
      "        all_possible_transitions  all_possible_states algorithms  accuracy  \\\n",
      "125112                      True                 True      l2sgd      0.44   \n",
      "125120                      True                 True      l2sgd      0.44   \n",
      "125121                      True                 True      l2sgd      0.44   \n",
      "125122                      True                 True      l2sgd      0.44   \n",
      "125128                      True                 True      l2sgd      0.44   \n",
      "\n",
      "        precision  recall  f1_score  \n",
      "125112     0.3954  0.8469    0.5355  \n",
      "125120     0.4149  0.8469    0.5537  \n",
      "125121     0.3779  0.8469    0.5186  \n",
      "125122     0.3648  0.8469    0.5099  \n",
      "125128     0.4149  0.8469    0.5537  \n"
     ]
    }
   ],
   "source": [
    "crf_sequence_results = pd.read_csv('sequenced_hyperparameter_results.csv', sep=';')\n",
    "\n",
    "top_5_sequence_lbfgs_accuracy = get_top_5_by_metric(crf_sequence_results, 'lbfgs', 'accuracy')\n",
    "top_5_sequence_lbfgs_precision = get_top_5_by_metric(crf_sequence_results, 'lbfgs', 'precision')\n",
    "top_5_sequence_lbfgs_recall = get_top_5_by_metric(crf_sequence_results, 'lbfgs', 'recall')\n",
    "top_5_sequence_lbfgs_f1_score = get_top_5_by_metric(crf_sequence_results, 'lbfgs', 'f1_score')\n",
    "\n",
    "print(top_5_sequence_lbfgs_accuracy)\n",
    "top_5_sequence_lbfgs_accuracy_params = extract_params(top_5_sequence_lbfgs_accuracy,'sequence-level')\n",
    "top_5_sequence_lbfgs_precision_params = extract_params(top_5_sequence_lbfgs_precision,'sequence-level')\n",
    "top_5_sequence_lbfgs_recall_params = extract_params(top_5_sequence_lbfgs_recall,'sequence-level')\n",
    "top_5_sequence_lbfgs_f1_score_params = extract_params(top_5_sequence_lbfgs_f1_score,'sequence-level')\n",
    "\n",
    "top_5_sequence_l2sgd_accuracy = get_top_5_by_metric(crf_sequence_results, 'l2sgd', 'accuracy')\n",
    "top_5_sequence_l2sgd_precision = get_top_5_by_metric(crf_sequence_results, 'l2sgd', 'precision')\n",
    "top_5_sequence_l2sgd_recall = get_top_5_by_metric(crf_sequence_results, 'l2sgd', 'recall')\n",
    "top_5_sequence_l2sgd_f1_score = get_top_5_by_metric(crf_sequence_results, 'l2sgd', 'f1_score')\n",
    "print(top_5_sequence_l2sgd_accuracy)\n",
    "\n",
    "top_5_sequence_l2sgd_accuracy_params = extract_params(top_5_sequence_l2sgd_accuracy,'sequence-level')\n",
    "top_5_sequence_l2sgd_precision_params = extract_params(top_5_sequence_l2sgd_precision,'sequence-level')\n",
    "top_5_sequence_l2sgd_recall_params = extract_params(top_5_sequence_l2sgd_recall,'sequence-level')\n",
    "top_5_sequence_l2sgd_f1_score_params = extract_params(top_5_sequence_l2sgd_f1_score,'sequence-level')\n",
    "\n",
    "params_list = top_5_sequence_lbfgs_accuracy_params + top_5_sequence_lbfgs_precision_params + top_5_sequence_lbfgs_recall_params + top_5_sequence_lbfgs_f1_score_params + top_5_sequence_l2sgd_accuracy_params + top_5_sequence_l2sgd_precision_params + top_5_sequence_l2sgd_recall_params + top_5_sequence_l2sgd_f1_score_params  \n",
    "unique_params_set = {tuple(param.items()) for param in params_list}\n",
    "unique_params_list = [dict(param) for param in unique_params_set]\n",
    "\n",
    "best_results_df = pd.DataFrame(unique_params_list)\n",
    "\n",
    "best_results_df.to_csv('best_results_sequence.csv', sep=';', encoding=\"utf-8\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
